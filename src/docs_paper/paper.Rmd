---
title: Understanding models for spatial structure in small-area estimation
author:
  - name: Adam Howes
    email: ath19@ic.ac.uk
    affiliation: A
    corresponding: ath19@ic.ac.uk
  - name: Jeffrey W. Eaton
    affiliation: B
  - name: Seth R. Flaxman
    affiliation: C
address:
  - code: A
    address: Department of Mathematics, Imperial College London
  - code: B
    address: MRC Centre for Global Infectious Disease Analysis, Imperial College London
  - code: C
    address: Department of Computer Science, University of Oxford
abstract: |
  |  **Background:** Spatial correlation between small-areas is typically accounted for within a generalised linear mixed model setting using spatial random effects. However, for some geometries, commonly used models for spatial random effects based upon adjacency relations, like the Besag model, make unrealistic and unsatisfying spatial assumptions. Furthermore, they do not take into account that across many settings areal data is generated by aggregating continuous point data. Defining spatial random effects which instead correspond to aggregated Gaussian processes gives a more intuitively convincing correlation structure, and allows tools from kernel methods to be used in models for areal data.
  |
  |  **Methods:** In a simulation study, we used a proper scoring rule to evaluate the performance of different spatial random effect specifications. We performed these simulations under model misspecification and across a range of vignette and realistic geometries with different regularities. We also compared model performance in estimating district-level HIV prevalence from PHIA household survey data across four countries in sub-Saharan Africa, using cross-validation and spatial cross-validation.
  |
  |  **Results:**
  |
  |  **Conclusions:**

author_summary: |
  Author summary

bibliography: citations.bib
output:
  rticles::elsevier_article:
    number_sections: true
    includes:
      in_header: preamble.tex
# plos.csl can be download and used locally
csl: http://www.zotero.org/styles/plos
---

```{r echo = FALSE}
options(scipen = 100)
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  dpi = 320,
  cache = TRUE,
  out.width = "95%",
  fig.align = 'center'
)

comma <- function(x) formatC(x, format = "d", big.mark = ",")
```

# Introduction

Spatial random effects are frequently used to model spatial variation in areal data [@haining2003spatial; @cramb2018investigation].
Gaussian Markov random fields (GMRFs) [@rue2005gaussian], which combine a Gaussian distribution with Markov conditional independence assumptions between areas, are the most common class of models used to specify spatial random effects.
Using a GMRF typically reflects the assumption that observations made in areas close together are correlated, and more distant relationships may be ignored.
The simplest GMRF model is arguably that of @besag1991bayesian, where information is borrowed equally from each adjacent area.
This model requires minimal additional modelling choices and is widely implemented, including as a part of the `R-INLA` package [@rue2017bayesian], popular within spatial statistics.
Use of this model is widespread, including in agriculture [@oliver2015soil], ecology [@saracco2010modeling], epidemiology [@lawson2013statistical], image analysis [@schmid2006bayesian], neuroscience [@gossl2001bayesian] and public health [@dwyer2015drinking].
However, for irregular geometries like the administrative divisions of a country, the assumptions made by the Besag model about space are unrealistic.
In this work, we set out to test the hypothesis that incorporating spatial structure more faithfully to the specific geometry would improve the performance of small-area estimation models, and in doing so provide practical recommendations and further understanding of models for spatial structure.
<!-- @gutreuter2019improving use the SAR model, which is still adjacency based but is not exactly the Besag model--restructure introduction to be more general and include introduction of other adjacency based models (which all have the same criticisms)? -->

Our motivating application is the small-area estimation of HIV epidemic indicators in sub-Saharan Africa.
Estimates are required to help plan, implement, and evaluate the success of programmes, ensuring that available resources are most effectively used to respond to the epidemic [@hallett2016evaluation; @cuadros2017mapping].
Household surveys provide nationally represenative data about the general population, but are expensive to carry out and as such have small sample sizes at a district level.
Although auxiliary covariates can be used to aid estimation, data on the covariates most strongly associated with HIV, such as sexual risk behaviour or the prevalence of male circumcision, often face similar measurement difficulties as the HIV indicators themselves.
Models including covariates have only been found to modestly improve predictions \citep[Supplementary Figure 20]{dwyer2019mapping}.
This stands in contrast to other infectious diseases like Malaria where transmission is driven by more predictive and easily-measurable environmental factors [@weiss2015re].
These circumstances foreground the importance of sharing information between districts via spatial smoothing in HIV mapping.

Within the GRMF framework, attempts to more accurately reflect irregular spatial structure have defined weights specifying the extent to which neighbours are related.
@duncan2017spatial compared seventeen methods for specifying these weights, but surprisingly did not find any which outperform the Besag model, though this conclusion was specific to the often-analysed Scottish lip cancer example, and based on the deviance information criteria (DIC) which is recommended against by @vehtari2017practical.
Another approach is to take into account that areal data is typically produced by aggregating higher resolution data.
The problem is then a particular instance of the broader challenge of inference about a variable at a different resolution to that it was observed at, known in geostatistics as the change-of-support problem [@gelfand2001change], which dates to foundational work on block kriging [@krige1951statistical; @matheron1976forecasting].
Ideas from change-of-support modelling are applied by @kelsall2002modeling to consider areal data as coming about by an aggregation of a continuously-indexed Gaussian process, resulting in a covariance structure between two areas given by the average covariance between two points chosen randomly from those areas.
This type of model is particularly natural in the log-Gaussian Cox process modelling framework [@li2012log; @diggle2013spatial; @taylor2015bayesian; @johnson2019spatially].
<!-- `lgcp` [@taylor2015bayesian] and `SDALGCP` [@johnson2019spatially] packages. -->
Inference for aggregated data has recently been advanced by @wilson2018pointless who consider the SPDE approach of @lindgren2011explicit, using `R-INLA`, and an empirical Bayes approach, using `TMB` [@kristensen2015tmb], and made available as a part of the `disaggregation` package [@nandi2020disaggregation].

Recognising that spatial heterogeneity in outcomes commonly reflects a combination of both spatially correlated processes and specific circumstances at a given location, it is usually recommended to use a random effect specification which includes both spatially structured and unstructured components.
Examples include the BYM2 model [@simpson2017penalising] and earlier convolutions such as the BYM [@besag1991bayesian], Leroux [@leroux2000estimation] or Dean [@dean2001detecting] models.
Evidence for this recommendation includes the comparison studies of @lee2011comparison and @riebler2016intuitive.
Improvements to the Besag model are likely transferable to improving these convolution models.
The Naomi HIV small-area estimation model [@eaton2021naomi], which motivates our work, uses both Besag and BYM2 spatial random effects, at different levels of the hierarchical model, and both models are of substantive practical interest.

The remainder of this paper is organised as follows.
Section \ref{sec:background} provides background on areal data and the Bayesian hierarchical modelling approach to small-area estimation.
In Section \ref{sec:ab}, we review developments in specifying spatial random effects based on adjacency, before presenting an alternative approach based on kernels in Section \ref{sec:ks}.
In Section \ref{sec:simulation} we compare models using simulated data, before applying them to mapping HIV prevalence in sub-Saharan Africa in Section \ref{sec:hiv}.
Finally, we discuss our conclusions and directions for future research in Section \ref{sec:discussion}.

<!-- @bradley2015spatio develop a framework for spatio-temporal change of support (STCOS) modelling, and a review of its implementation in \textsc{R} is provided by @raim2021spatio. -->
<!-- Lee find that Leroux model of @leroux2000estimation achieves consistently good performance across a range of spatial correlation settings. -->
<!-- @riebler2016intuitive reach a similar conclusion about both the Leroux and BYM2 model. -->

# Background \label{sec:background}

## Areal and point spatial data

Let $\Sc \subset \mathbb{R}^2$ be the study region, and the disjoint areas $\{A_i\}_{i = 1}^n$ be a spatial partition of $\Sc$.
Areal data are a type of spatial data where observations $y_i$ are associated to areas $A_i$.
Examples include the colour of a pixel, the minimum wage in a state, and the number of disease cases in a region.
Point data are another type of spatial data where instead observations $y(s)$ can be made at any location $s \in \Sc$ of a spatially-continuous stochastic process.

Areal data is often aptly conceptualised as arising from aggregation of point data, such that $y_i = \int_{A_i} y(s) \text{d}s$.
Exceptions include policies determined at an administrative level, such as the minimum wage or disease control measures, which have a genuinely discrete spatial structure.
<!-- Note that, for data of this sort, there is less clear justification for using spatial smoothing. -->
<!-- Realistically, data relate to many covariates, some number of which are likely have discrete spatial structure and others of which continuous spatial structure, such that the result is often an intermediate. -->
<!-- It may be possible to model this explicitly, though the result might look similar to what is achieved using e.g. BYM2. -->
If the areal data we observe are indeed an aggregation of point data, why not use the higher resolution point data in our models rather than areal data?
Explanations include that (a) the underlying point data are unobserved, (b) although point data are collected, they may not be accessible due to privacy constraints, administrative practicality or storage capacity, and (c) the point data are available, but we decide not to use them in the model.
In the final case (c), researchers may prefer to use area-level models as models for point data are typically more complex, require more data, are less immediately applicable to area-level policy making, and have higher computational burden.
Furthermore, seemly point data may actual be areal, such as data observed at polling stations or health facilities which individuals from the surrounding area travel to.
As such, choosing to model the underlying data generating mechanism as either areal or point is often a matter of pragmatism.

## Small-area estimation

Auto-correlation is an important property of most spatial processes.
Usually, outcomes for locations close together in space tend to be more similar than those far apart.
This fact is known as "Tobler's first law of geography" [@tobler1970computer] and, from a statistical point of view, is both a challenge and a benefit of working with spatial data.
Each observation provides less information than it would have had the samples been independent, making it more difficult to estimate global parameters.
However, spatial correlation can be used to improve local (indexed by a particular spatial location) parameter estimates particularly in parts of the study region where little to no information is available.

The latter benefit is basis for the statistical task of small-area estimation, which aims to produce reliable local estimates where small sample sizes lead to noisy data [@pfeffermann2013new].
In a spatial setting, this is often in small geographic areas, though the phrase "small-area" is not restricted to geographic areas and may be interpreted more broadly to mean any area where data are insufficient to make accurate local parameter inferences.
In the context of multilevel regression and post-stratification [@gelman1997poststratification], small-areas are generated by the intersection of demographic variables like age, gender and race, alongside geographic variables.
Due to the cost of gathering samples, a survey may be designed to give reliable estimates at at an aggregated level but not at a small-area level.
Although direct estimators of local parameters are unbiased, when data are sparse the total error may be reduced by accepting some bias in exchange for reduced variance using so-called indirect estimators.
Smoothing approaches use information from similar units to "borrow strength" from one parameter to another, with determining precisely what is meant by "similar" a central challenge.
For a recent review of both design-based and model-based approaches to spatial analysis of health-indicators, including both area and unit-level analysis, see @wakefield2020small.

## Bayesian model-based approach and latent Gaussian models \label{sec:lgm}

Bayesian hierarchical models are an attractive framework for small-area estimation, whereby areal data $y$ corresponding to the areas $\{A_i\}_{i = 1}^n$, are modelled using a three-layer structure [@berliner1996hierarchical; @cressie2015statistics; @rao2015small] given by
\begin{alignat}{2}
&\text{(Observations)}  &        y_i &\sim p(y_i \, | \, g^{-1}(x_i), \theta), \quad i = 1, \ldots, n, \label{eq:data} \\
&\text{(Latent field)}  &        x &\sim p(x \, | \, \theta), \label{eq:process} \\
&\text{(Parameters)}    & \qquad \theta &\sim p(\theta), \label{eq:parameters}
\end{alignat}
where $x$ is the $n$-dimensional latent field, $\theta$ are the $m$-dimensional parameters, $m < n$, and $g$ is a link function.
Spatial structure is modelled at the level of the latent field, and the observation model, typically either binomial or Poisson, is conditionally independent and identically distributed $p(y \, | \, x, \theta) = \prod_{i = 1}^n p(y_i \, | \, x_i, \theta)$.
As small-area estimation models are descriptive rather than mechanistic, it is natural [@best2005comparison] to use a flexible and computationally efficient Gaussian distribution $x \sim \mathcal{N}(\mu, \Sigma)$ for the latent field.
Three-layer models with Gaussian latent fields comprise a wide array of popular models, including generalised linear mixed models (GLMMs), and have been collectively studied under the title latent Gaussian models (LGMs) [@rue2009approximate].

## Spatial random effects

The latent field in a LGM is comprised a constant mean $\mu$, known also as the fixed effects, and spatial random effects $\phi \sim \mathcal{N}(0, \Sigma)$.
The mean may be modelled using a linear predictor $\mu_i = \beta_0 + z_i^\top \beta$, where $(\beta_0, \beta)$ are regression parameters corresponding to areal covariates $z_i = (z_{i,1}, \ldots, z_{i,p})^\top$.
We focus on the spatial random effects $\phi$, whose role is to capture the spatial structure between areas not already accounted for in the mean.
If no spatial structure remains after inclusion of covariates in the mean, independent and identically distributed (IID) random effects $\phi_i \sim \N (0, \tau_\phi^{-1})$ should be used, where $\tau_\phi$ is a shared precision.
Exploratory data analysis techniques such as visual inspection or Moran's $I$ coefficient [@cliff1981spatial] may be used to determine if there remains any spatial auto-correlation in the data.
<!-- TODO: Add calculation of Moran's $I$ to my HIV survey data-sets. -->
Specifying $\phi$ amounts to specifying the entries of a precision or covariance matrix, as we discuss in the following sections.

# Spatial random effects using adjacency \label{sec:ab}

```{r geometry-graph-zwe, fig.align="center", fig.cap="A map of the districts of Zimbabwe together with the corresponding adjacency graph structure $\\mathcal{G}$. \\label{fig:geometry-graph-zwe}"}
knitr::include_graphics("depends/geometry-graph-zwe.pdf")
```

## Besag \label{sec:besag}

One way to encode spatial structure between areas is by using a symmetric relation, where $i \sim j$ if the areas $A_i$ and $A_j$ are adjacent or neighbouring.
Adjacency is often defined by a shared border, though other choices, such as inclusion of second or higher-degree neighbours [@paciorek2013spatial], are also possible.
The Besag model [@besag1991bayesian] is a type of improper conditional auto-regressive (ICAR) model where the full conditional distribution of the $i$th spatial random effect is given by
\begin{equation}
    \phi_i \, | \, \phi_{-i} \sim \N \left(\frac{1}{n_{\delta i}} \sum_{j: j \sim i} \phi_j, \frac{1}{n_{\delta i}\tau_\phi}\right), \label{eq:besag}
\end{equation}
where $\delta i$ is the set of neighbours of $A_i$ with cardinality $n_{\delta i} = |\delta i|$ and $\phi_{-i} = (\phi_1, \ldots, \phi_{i - 1}, \phi_{i + 1}, \ldots, \phi_n)^\top$ is the vector of spatial random effects with the $i$th entry removed.
The conditional mean of the random effect $\phi_i$ is the average of its neighbours $\{\phi_j\}_{j \sim i}$ and the precision $n_{\delta i}\tau_\phi$ is proportional to the number of neighbours $n_{\delta i}$.
By Brook's lemma \cite[Chapter 2]{rue2005gaussian} the set of full conditionals of the Besag model are equivalent to the Gaussian Markov random field (GMRF) given by
\begin{equation}
    \phi \sim \mathcal{N}(0, \tau_\phi^{-1} R^{-}), \label{eq:gmrf}
\end{equation}
where $R^{-}$ is the generalised inverse of the rank-deficient structure matrix $R$, so-called because it defines the \textit{structure} of the precision matrix, with entries
\begin{equation}
    R_{ij} =
    \begin{cases}
        n_{\delta i}, & i = j \\
        -1, & i \sim j \\
        0, & \text{otherwise.}
    \end{cases}
\end{equation}
The Markov property arises due to the conditional independence structure $p(\phi_i \, | \, \phi_{-i}) = p(\phi_i \, | \, \phi_{\delta i})$ whereby each area only depends on its neighbours.
This is reflected in the sparsity of $R$ whereby $\phi_i \perp \phi_j \, | \, \phi_{-ij}$ if and only if $R_{ij} = 0$.
The structure matrix $R$ may also be expressed as the Laplacian of the adjacency graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ with vertices $v \in \mathcal{V}$ corresponding to each area and edges $e \in \mathcal{E}$ between vertices $i$ and $j$ when $i \sim j$.
Figure \ref{fig:geometry-graph-zwe} shows the adjacency graph for the districts of Zimbabwe alongside the geometry.
Shortly, in Section \ref{sec:concerns} we discuss the appropriateness of using the graph rather than the complete geometry.

Rewriting Equation \ref{eq:gmrf}, the probability density function of $\phi$ is
\begin{equation}
    p(\phi)
    \propto \exp \left( -\frac{\tau_\phi}{2} \phi^\top R \phi \right)
    \propto \exp \left( -\frac{\tau_\phi}{2} \sum_{i \sim j} (\phi_i - \phi_j)^2 \right). \label{eq:pdfphi}
\end{equation}
This density is a function of the pairwise differences $\phi_i - \phi_j$ and so is invariant to the addition of a constant $c$ to each entry $p(\phi) = p(\phi + c1)$, leading to an improper uniform distribution on the average of the $\phi_i$.
If $\mathcal{G}$ is connected, in that by traversing the edges, any vertex can be reached from any other vertex, then there is only one impropriety in the model and $\text{rank}(R) = n - 1$, while if $\mathcal{G}$ is disconnected, and composed of $n_c \geq 2$ connected components with index sets $I_1, \ldots, I_{n_c}$, then the corresponding structure matrix $R$ has rank $n - n_c$ and the density is invariant to the addition of a constant to each of the connected components $p(\phi_{I}) = p(\phi_{I} + c1)$ where $I = I_1, \ldots, I_{n_c}$.

## Concerns about the Besag model's representation of space \label{sec:concerns}

\begin{figure}
\centering
\includegraphics{depends/maup1.pdf}
\caption{Each of these four geometries corresponds to the same adjacency graph.}
\label{fig:tikz1}
\end{figure}

\begin{figure}
\centering
\includegraphics{depends/maup2.pdf}
\caption{A sequence of geometries where the number of neighbours of area one grows by one at each iteration.}
\label{fig:tikz2}
\end{figure}

\begin{figure}
\centering
\includegraphics{depends/maup3.pdf}
\caption{Each of the shaded areas are split into two moving from geometry (i) to (ii).}
\label{fig:tikz3}
\end{figure}

The Besag model was originally proposed for use in image analysis, where areas correspond to pixels arranged in a regular lattice structure.
Since then, it has seen wider use, including in situations where the spatial structure is less regular.
There are a number of concerns about the model's applicability to this broader setting, which we highlight below.
Closely linked are the modifiable areal unit problem [@openshow1979million] whereby statistical conclusions change as a result of seemingly arbitrary changes in data aggregation, and the challenge of ecological inference and the ecological fallacy [@wakefield2010aggregation], which applies particularly to inference about individuals and groups.
<!-- Missing an item about potential loss of information by using a sparse matrix, though I don't actually think this is very important. -->

### Adjacency compression

Summarising all spatial information with an adjacency graph represents a loss of information.
Many geometries share the same adjacency graph, and therefore the same probability model, as illustrated by Figure \ref{fig:tikz1}.
This fact is not concerning in itself, though it prompts consideration as to whether the class of geometries with the same adjacency graph is sufficiently similar to merit identical models.\footnote{The regularity of realistic geometries may help to constrain each class to be more similar than it strictly has to be. In other words, although pathological geometries can be constructed, they are implausible in statistical practise and so not of great concern to us here.}
It is intuitive that the more regular the spatial structure the less information is lost in compression to an adjacency graph.
In image analysis, very little spatial information is lost in compression a lattice structure to an adjacency graph.
On the other hand, the regions of a country, determined by political and geographic forces, tend to display greater irregularity.
As such, the appropriateness of adjacency compression varies by the type of geometry common to the application setting.

### Mean structure

A feature specific to the Besag model is that all adjacent areas count equally.
This assumption is unsatisfying: for most geometries, we expect some areas to be more highly correlated to some neighbours than to others.
Figure \ref{fig:tikz1} illustrates a number of heuristic features for neighbour importance, including length of shared border in geometry (iii), and the proximity of centers of mass in geometry (iv).
This may be remedied using more general weighted ICAR models, as we outline in Section \ref{sec:icar}.

### Variance structure

A striking feature of Equation \ref{eq:besag} is that the precision of $\phi_i$ is proportional to its number of neighbours $n_{\delta i}$.
It follow that as $n_{\delta i} \to \infty$ then $\text{Var}(\phi_i) \to 0$.
This is illustrated by Figure \ref{fig:tikz2} where the area on the right is repeatedly divided such that its number of neighbours increases by one at each step.
This property is a consequence of averaging the conditional mean over a greater number of areas, which, in certain situations, can correspond to a greater amount of information.
However, if the amount of information in the shaded area remains fixed, it is inappropriate that $\text{Var}(\phi_1)$ should tend to zero just as a result of drawing additional, arbitrary, boundaries.
In the image analysis setting this modelling assumption is reasonable: each pixel represents a fixed amount of information and a higher pixel density represents a greater amount of information.
On the other hand, in public health and epidemiology, drawing boundaries to create additional regional areas cannot be expected to correspond to a greater amount of information and this assumption is not appropriate.

Suppose we fit a Besag model upon identical data using each of the two geometries in Figure \ref{fig:tikz3}.
If the spatial variation is relatively smooth, dividing the shaded areas into two will result in a lower estimated variance $\sigma^2_\phi$ in geometry (ii) as compared with geometry (i) because there will appear to be less variation between neighbouring areas.
This problem does not only apply locally: since the effect of $\sigma^2_\phi$ applies everywhere, the smoothing will change even in unaltered parts of the study region.

## Weighted ICAR \label{sec:icar}

The Besag model is a special case of a more general class of (zero-mean) ICAR models in which each neighbour may not be weighted equally.
These models can be specified in terms of scaled weights $\{b_{ij}\}_{j \sim i}$ and a precision vector $\kappa = (\kappa_1, \ldots, \kappa_n)^\top$ such that $\phi_i \, | \, \phi_{-i} \sim \N ( \sum_{j: j \sim i} b_{ij} \phi_j, (\kappa_i \tau_\phi)^{-1} )$.
The structure matrix $R$ corresponding to the above full conditionals is given by $R = D_\kappa(I - B)$, where $B$ has the entries $b_{ij}$ for $i \sim j$, diagonal entries $b_{ii} = 0$ and $b_{ij} = 0$ for $i \nsim j$ and the matrix $D_\kappa$ is given by $\text{diag}(\kappa_1, \ldots, \kappa_n)$.
As the structure matrix is symmetric we must have the condition $-b_{ij}\kappa_i = -b_{ji}\kappa_j$.
To meet this condition, it is often simpler to use an unscaled weights matrix $W = D_\kappa B$ such that $R = D_\kappa - W$.
For example, in the Besag model $W$ corresponds to the adjacency matrix.
The scaled weights can then be recovered by $b_{ij} = w_{ij} / \kappa_i$ where $\kappa_i = \sum_{k: k \sim i} w_{ik}$.
A thorough discussion of methods for specifying $W$ is provided by @duncan2017spatial.
Much of the work in this area focuses on the case where the geometry is a lattice.

## BYM2 \label{sec:bym2}

Often, as well as spatial structure, there exists IID over-dispersion in the residuals and it is inappropriate to use purely spatially structured random effects in the model.
The Besag-York-Mollié (BYM) model of @besag1991bayesian, accounts for this in a natural way by decomposing the spatial random effect $\phi = v + u$ into a sum of an unstructured IID component $v$ and a spatially structured Besag component $u$, each of which with their own respective precision parameters $\tau_v$ and $\tau_u$.
The resulting distribution is
\begin{equation}
    \phi \sim \N(0, \tau_v^{-1} I + \tau_u^{-1} R^{-}) \label{eq:bym}.
\end{equation}
Including both $v$ and $u$ is intended to enable the model to learn the relative extent of the unstructured and structured components via $\tau_v$ and $\tau_u$.
However, in this specification, scaling of the Besag precision matrix $Q$ is not taken into account despite this issue being particularly pertinent when dealing with multiple sources of noise.
In particular, placing a joint prior $(\tau_u, \tau_v) \sim p(\tau_u, \tau_v)$ which doesn't privilege either component is more easily accomplished if $Q$ and $I$ have the same scale.
Additionally, supposing we have a prior belief that the over-dispersion is primarily IID and $v$ accounts for the majority of the dispersion, then it is not immediately obvious how to represent this belief using $p(\tau_u, \tau_v)$, without inadvertently altering the prior about the overall variation.
This highlights identifiability issues of the parameters $(\tau_u, \tau_v)$ resulting from them not being orthogonal.
Building on the models of @leroux2000estimation and @dean2001detecting which tackle this the identifiability problem, but do not scale the spatially structured noise, @simpson2017penalising propose a reparameterisation $(\tau_v, \tau_u) \mapsto (\tau_\phi, \pi)$ of the BYM model known as the BYM2 model and given by
\begin{align}
\phi = \frac{1}{\tau_\phi} \left( \sqrt{1- \pi} \, v + \sqrt{\pi} \, u^\star \right), \label{eq:bym2}
\end{align}
where $\tau_\phi$ is the marginal precision of $\phi$, $\pi \in [0, 1]$ gives the proportion of the marginal variance explained by each component, and $u^\star$ is a scaled version of $u$ with precision matrix given by the scaled structure matrix $R^\star$ (see Appendix).
When $\pi = 0$ the random effects are IID, and when $\pi = 1$ the random effects follow the Besag model.
To borrow an analogy, the parameterisation $(\tau_v, \tau_u)$ is like having one hot water and one cold water tap, whereas the parameterisation $(\tau_\phi, \pi)$ is like a mixer tap where the amount of water and its temperature can be adjusted separately [@rue2020comment].

# Spatial random effects using kernels \label{sec:ks}

<!-- % Cast the ICAR models as an example of a kernel? -->

## Areal kernels

Section \ref{sec:ab} reviewed ways to construct spatial random effect precision matrices using an adjacency relation.
Another approach is to define the covariance matrix using an areal kernel function $K: \mathcal{P}(\Sc) \times \mathcal{P}(\Sc) \to \mathbb{R}$ which gives a measure of similarity between two areas, where $\mathcal{P}$ denotes the power set and $\mathcal{P}(\Sc)$ is the space of subsets of the study region.
If $K$ is positive semi-definite, then we define areal kernel spatial random effects by
\begin{equation}
    \phi \sim \mathcal{N}(0, \frac{1}{\tau_\phi} K), \label{eq:arealkernel}
\end{equation}
where the $n \times n$ Gram matrix $K$ with entries $K_{ij} = K(A_i, A_j)$ is a valid covariance matrix.
Here, we place $\tau_\phi$ outside of the Gram matrix, analogous to the relation of the precision and structure matrices.

Most well-known spatial process models define the correlation structure between a pair of points using a kernel $k: \mathcal{S} \times \mathcal{S} \to \mathbb{R}$.
We use a simple method to construct $K$ from $k$, namely averaging the kernel $k$ computed on some collection of points from within each area.
As such, $K$ is described as a kernel on sets in the multiple instance learning literature [@gartner2002multi].
Although it may be possible to learn the method for combining kernels from data [@gonen2011multiple], we do believe that this is feasible in the small-area estimation setting, and instead hope to construct areal kernels which represent our prior beliefs about the spatial process.

## Centroid kernel

The simplest approach is to use a single point, especially one which is representative of the area, a natural choice being the centroid $c_i \in A_i$ given by the arithmetic mean of the latitude and longitude.
This results in the centroid kernel
\begin{equation}
    K(A_i, A_j) = k(c_i, c_j).
\end{equation}
<!-- More broadly, given a weighting distribution $W_i$ with probability density proportional to $w_i(s)$ over $A_i$, weighted centroids could be used in the above equation. -->
The centroid kernel has been used by @wakefield1999spatial in an environmental epidemiology setting and @best2005comparison in a model comparison study, both choosing the exponential kernel $k(s_i, s_j) = \exp \left( - |s_i - s_j| / l \right)$; as well as more recently by @teh2021efficient as a part of a spatio-temporal Gaussian process model to infer the reproduction number of COVID-19.
@wakefield1999spatial fix the length-scale $l$ using a semi-variogram and @best2005comparison place a prior on the inverse length-scale.
\citet[Section 3]{best2005comparison} simulated data representing heterogeneous exposure to air pollution, including elevated rates of exposure near two hypothetical point source locations, and found that the centroid kernel tended to over-smooth the high-risk areas, though it is unsuprising that a stationary covariance would struggle to recover non-stationary structure.

## Integrated kernel \label{sec:ik}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{depends/integration-method.pdf}
\caption{Three ways to choose integration points with $L_i = 10$ for all $i$ in Malawi, as implemented by \texttt{sf::st\_sample}.}
\label{fig:41}
\end{figure}

Rather than attempting to choose a single representative point, an alternative is to represent the whole area by integrating the kernel over the areas of interest.
This results in the integrated kernel
\begin{equation}
K(A_i, A_j) = \frac{1}{|A_i||A_j|} \int_{A_i} \int_{A_j} k(s, s') \text{d} s \text{d} s', \label{eq:ik1}
\end{equation}
which is equivalent to the covariance structure obtained by aggregating a spatially continuous Gaussian process with kernel $k$ over the areal partition.
Models of this sort have been studied in the machine learning literature under the name aggregated Gaussian processes [@law2018variational; @tanaka2019spatially; @yousefi2019multi; @hamelijnck2019multi; @2021arXiv210501460Z].
<!-- % For example, @law2018variational develop a variational Bayesian inference method for aggregated observation models and @tanaka2019spatially consider aggregation over a linear combination of latent Gaussian processes, each of which is associated to data corresponding to a different partition of the study region. -->
Unlike for the centroid kernel where $K_{ii} = 1$ for all $i$, the marginal variance of the $i$th spatial random effect $K_{ii} = K(A_i, A_i)$ varies depending on the area: becoming smaller for more compact areas and larger for areas which are of greater extent or more spread out.

The log-Gaussian Cox Process framework [@diggle2013spatial] also naturally arrives at the integrated kernel formulation.
A Cox process is an inhomogeneous Poisson process with a continuous stochastic intensity function $\{ x(s), s \in \Sc \}$ such that conditional on the realisation of $x(s)$ the number of points in any area $A_i$ follows a Poisson distribution.
The rate parameter of this Poisson distribution is explicitly aggregated as follows
\begin{equation}
y_i \, | \, x(s) \sim \text{Poisson} \left(\int_{s \in A_i} x(s) \text{d}s \right).
\end{equation}
In a LGCP the log intensity $\log x(s) = \eta(s)$ is modelled using a Gaussian process prior $\eta(s) \sim \mathcal{GP}(\mu(s), k(s, s'))$.
@johnson2019spatially obtain Equation \ref{eq:ik2} by considering a discrete Poisson log-linear mixed model approximation to a continuous LGCP, whereby $\eta(s)$ is approximated by a piecewise constant $\eta_i = \mu_i + \phi_i$ in each area $A_i$^[@johnson2019spatially use points generated from a class of inhibition processes which combine sequential inhibition with rejection sampling to evaluate the integral.].
The $i$th discrete spatial random effect is then $\phi_i = \int_{A_i} w_i(s) \phi(s) \text{d}s$,
with covariance structure
\begin{equation}
\text{Cov} \left( \int_{A_i} w_i(s) \phi(s) \text{d}s, \int_{A_j} w_j(s') \phi(s') \text{d}s' \right)
= \int_{A_i} \int_{A_j} w_i(s) w_j(s') k(s, s') \text{d}s\text{d}s',
\end{equation}
corresponding to an areal integrated kernel with a logarithmic link function and Poisson likelihood.

Disaggregation regression (also known as downscaling or interpolation) is another closely related approach which, rather than using the aggregate nature of areal observations as primarily a route towards better area-level estimates, as is our focus, aims to producing high-resolution or point-level estimates from areal observations [@utazi2019spatial; @nandi2020disaggregation].
<!-- Accurate point-level estimates are close to being a necessary intermediate goal towards obtaining accurate area-level estimates. -->
<!-- Disaggregation is challenging without auxiliary information. -->

A benefit of the integration approach is that, if available, additional information accounting for heterogeneity over $A_i$ may be incorperated into the model.
This can be accomplished using weighting distributions $\{W_i\}$ which represent an unequal contribution of each point to the similarity measure, to give a weighted integrated kernel
\begin{equation}
K(A_i, A_j) = \frac{1}{|A_i||A_j|}\int_{A_i} \int_{A_j} w_i(s) w_j(s') k(s, s') \text{d} s \text{d} s', \label{eq:ik2}
\end{equation}
This may be useful in disease mapping, where we expect regions with populations who live close to their shared border to be more strongly correlated than regions whose populations live far apart, which could be accounted for by weighting according to a high resolution measure of population density.

If areal kernel spatial random effects are created using the integrated kernel, then aggregation occurs at the level of the latent field in the three stage model rather than at the level of the data.
This corresponds to a generative model of the form $y_i \sim p(y_i \, | \,  g^{-1}(x_i))$, with $x_i = |A_i|^{-1}\int_{A_i} x(s) \text{d} s$.
If the link function $g$ is the identity or linear then aggregation at the level of the latent field is equivalent to aggregation at the level of the data.
On the other hand, for non-linear link functions $g$ such as the exponential or logistic, the generative model does not match the proposed data generating process $y_i = |A_i|^{-1}\int_{A_i} y(s) \text{d}s$.
<!-- Add equations for mean $\mathbb{E}(y_i)$ and variance $\mathbb{V}(y_i)$ of under this model, as a function of $g$. -->
<!-- Explain under what circumstances we believe this approximation to be acceptable. -->

Most of the time we do not expect to be able to calculate the integral in Equation \ref{eq:ik2} analytically.
Instead, given $n$ collections of $L_i$ samples $\{s^{(i)}_l \}_{l = 1}^{L_i} \sim \mathcal{U}(A_i)$ drawn uniformly from each area then the integral may be approximated using Monte Carlo by the double sum
\begin{equation}
K(A_i, A_j) \approx \frac{1}{L_i L_j} \sum_{l = 1}^{L_i} \sum_{m = 1}^{L_j}
w_i \left( s^{(i)}_l \right) w_j \left( s^{(j)}_m \right)
k \left( s^{(i)}_l, s^{(j)}_m \right). \label{eq:mcintegratedkernel}
\end{equation}
Equivalently, samples drawn from $W_i$ may be used without weighting by $w_i(s)$.
Integration points may also be selected by some deterministic process, and used in Equation \ref{eq:mcintegratedkernel} to give a numerical integration estimate of the kernel.
As with learning the way in which the kernels should be combined, in more data rich settings it may be possible to learn the integration points [@campbell2019automated].
Taking any of these approaches requires $\mathcal{O}(\sum_{i = 1}^n \sum_{j = 1}^n L_i L_j)$ evaluations of the kernel $k$ to compute the $n \times n$ Gram matrix $K$.
This imposes a significant computational cost if the Gram matrix is often recomputed during inference, as is the case in MCMC when any of the kernel hyperparameters are learnt, placing a limit on the number of samples or integration points it is feasible to use.
To make inference more feasible, @kelsall2002modeling reduce the number of Gram matrix constructions and inversions required, by using a discrete hyperparameter prior.

<!-- A unified view on Bayesian varying coefficient models by Franco-Villoria et al. -->

# Simulation study \label{sec:simulation}

\begin{figure}
\centering
\includegraphics{depends/simulation-geometries.pdf}
\caption{The seven simulation geometries that we considered.}
\label{fig:51}
\end{figure}

We tested the ability of inferential models with varying spatial random effect specifications to accurately recover small-area quantities.
The data and modelling choices were designed with a spatial epidemiology setting in mind, and are similar to those used in Section \ref{sec:hiv} where we considered models for HIV prevalence using data from national household surveys in sub-Saharan Africa.
The \textsf{R} [@R2021] code used is available from `github.com/athowes/areal-comparison`.
We used the `orderly` package [@orderly] for reproducible research.

## Synthetic data-sets

\begin{table}[]
\small
\begin{tabularx}{\textwidth}{@{}lX@{}}
\toprule
Simulation model & Additional details \\
 \midrule
\hypertarget{S1}{S1}. \textit{IID} & $\phi \sim \mathcal{N}(0, I_n)$ \\
\hypertarget{S2}{S2}. \textit{Besag} & $\phi \sim \mathcal{N}(0, (R^\star)^{-})$ as described in Section \ref{sec:besag} where $R^\star$ is the scaled structure matrix \\
\hypertarget{S3}{S3}. \textit{IK} & $\phi \sim \mathcal{N}(0, K^\star)$ as described in Section \ref{sec:ik} where $K_{ij}$ is calculated via Equation \ref{eq:mcintegratedkernel} using the Mat\'{e}rn kernel with $\nu = 3/2$, $l = 2.5$ and $L_i = 100$ samples are drawn uniformly from each area.
Like the Besag model, we scaled the Gram matrix to have generalised variance one \\
\bottomrule
\end{tabularx}
\caption{The three simulation models from which we generate $\phi$.}
\label{tab:simulationmodels}
\small
\end{table}

We studied robustness to spatial misspecification, by simulating synthetic data-sets from three known data generating processes.
The spatial random effects $\phi$ were generated according to IID, Besag and integrated kernel (IK) simulation models (Table \ref{tab:simulationmodels}).
We then generated synthetic data $y = (y_1, \ldots, y_n)^\top$ of a form analogous to a household survey whereby $y_i \sim \text{Bin}(m_i, \rho_i)$ where the probabilities $\rho_i \in [0, 1]$ are linked to the latent random variables $x_i \in \mathbb{R}$ via
\begin{equation}
\log \left( \frac{\rho_i}{1 - \rho_i} \right) = x_i = \beta_0 + \phi_i, \quad i = 1, \ldots, n.
\end{equation}
We fixed the sample sizes to $m_i = 25$ for all $i$, the intercept parameter as $\beta_0 = -2$ and the spatial random effect precision parameter as $\tau_\phi = 1$.
We used seven different geometries: the four vignette geometries in Figure \ref{fig:tikz1}, which share an adjacency graph, as well as three more realistic geometries, a $6 \times 6$ lattice grid, the 33 districts of Côte d'Ivoire and the 36 congressional districts of Texas (Figure \ref{fig:51}).
These more realistic geometries were chosen to represent variation over spatial regularity, allowing us to test how model performance varies by geometry regularity.
For each combination of spatial random effect and geometry we replicated the simulation process above 200 times to generate a total of 1400 synthetic data-sets.

## Inferential models

We fit eight inferential models, each of which differing in its spatial random effect specification (Table \ref{tab:inferentialmodels}).

\begin{table}
\small
\begin{tabularx}{\textwidth}{llX}
\toprule
Inferential model & Algorithm & Additional details \\
 \midrule
\hypertarget{I1}{I1}. \textit{Constant} & INLA &
No spatial random effects \label{row:I1} \\
\hypertarget{I2}{I2}. \textit{IID} & INLA &
$\phi \sim \mathcal{N}(0, \tau_\phi^{-1} I_n)$\\
\hypertarget{I3}{I3}. \textit{Besag} & INLA &
$\phi \sim \mathcal{N}(0, (\tau_\phi R^\star)^{-})$ following additional recommendations in \ref{app:freni}  \\
\hypertarget{I4}{I4}. \textit{BYM2} & INLA &
$\phi = \tau_\phi^{-1} \left( \sqrt{1- \pi} \, v + \sqrt{\pi} \, u^\star \right)$ with a $\text{Beta}(0.5, 0.5)$ prior on $\pi \in [0, 1]$ \\
\hypertarget{I5}{I5}. \textit{FCK} & INLA &
$\phi \sim \mathcal{N}(0, \tau_\phi^{-1} K)$ with $K_{ij} = k(c_i, c_j)$ where the length-scale $l$ is fixed \\
\hypertarget{I6}{I6}. \textit{CK} & NUTS & As in model \hypertarget{I5}{I5}, with length-scale prior $l \sim \mathrm{Inv{\text-}Gamma}(a, b)$ \\
\hypertarget{I7}{I7}. \textit{FIK} & INLA & $\phi \sim \mathcal{N}(0, \tau_\phi^{-1} K)$ with $K_{ij} = \frac{1}{10^2} \sum_{l = 1}^{10} \sum_{m = 1}^{10} k \left( s^{(i)}_l, s^{(j)}_m \right)$ \newline with hexagonal integration point spacing and fixed length-scale $l$ \\
\hypertarget{I8}{I8}. \textit{IK} & NUTS & As in model \hypertarget{I7}{I7}, with length-scale prior $l \sim \mathrm{Inv{\text-}Gamma}(a, b)$ \\
\bottomrule
\end{tabularx}
\caption{Each inferential model is implemented as a part of the \textsf{R} package \texttt{arealutils} available from \url{github.com/athowes/arealutils}.}
\label{tab:inferentialmodels}
\small
\end{table}

### Priors

We placed a half-Gaussian prior on the standard deviation [@gelman2006prior] such that $\sigma_\phi \sim \mathcal{N}_+(0, 2.5^2)$.
The weakly informative value 2.5 was chosen to avoid placing significant prior density on the region $\sigma_\phi > 5$, which after a logistic transformation facilitates variation on the probability scale very close to either zero or one, neither of which we assumed to be plausible.
A weakly informative $\mathcal{N}(-2, 1)$ prior was placed on $\beta_0$, setting most of the prior probability density for $\rho_i$ within a range $[0, 0.25]$ typical for a disease prevalence.

### Kernel model details

Following @stein1999interpolation, for the areal kernel models we used the Matérn kernel $k: \Sc \times \Sc \to \mathbb{R}$ given by
\begin{equation}
k(s, s') =
\frac{1}{2^{\nu - 1}\Gamma(\nu)} \left(\frac{\sqrt{2\nu}\lvert s - s' \rvert}{l}\right)^\nu
B_\nu\left(\frac{\sqrt{2\nu}\lvert s - s' \rvert}{l}\right), \label{eq:matern}
\end{equation}
where $B_\nu$ is the modified Bessel function of the second kind, $|s - s'|$ is the Euclidean distance between $s$ and $s'$, $\nu$ is the smoothness hyperparameter and $l$ is the length-scale hyperparameter on the latitude-longitude scale.
We fixed the smoothness parameter, which is otherwise typically unidentifiable from data, to be $3/2$, matching that used in simulation model \hyperlink{S3}{S3}, and convenient in that it simplifies Equation \ref{eq:matern} to be
\begin{equation}
k(s, s') = \left(1 + \sqrt{3} \lvert s - s' \rvert / l \right) \exp \left(- \sqrt{3} \lvert s - s' \rvert / l \right).
\end{equation}
Taking a similar approach to @best1999bayesian, in models \hyperlink{I5}{I5} and \hyperlink{I7}{I7} we fixed the length-scale such that points an average distance apart in the model have 1\% correlation  a priori, independent of the data.
In models \hyperlink{I6}{I6} and \hyperlink{I8}{I8}, we used a length-scale prior $l \sim \mathrm{Inv{\text-}Gamma}(a, b)$, with parameters $a$ and $b$ chosen for each model such that 1\% of the prior mass is below 0.1 and 1\% of the prior mass is above the maximum distance between points in the model [@betancourt2017robust].
For the integration points we set $L_i = 10$ using a hexagonal spacing structure, as with the central panel of Figure \ref{fig:51}.
Though note `sf::st_sample` with `type = "hexagonal"` does not guarantee exactly the specified number of samples are returned [@pebesma2018sf].
We are limited to this relatively small number by the computational costs of Model \hyperlink{I8}{I8}.
For Model \hyperlink{I6}{I6} although it is feasible to use a much larger number of integration points, since the Gram matrix is only computed once, we chose not to for comparability.

## Inference algorithms

In models \hyperlink{I1}{I1}-\hyperlink{I5}{I5} choosing a Gaussian distribution for $\beta_0$ ensures that the latent random variables are Gaussian and the model is a LGM, facilitating use of the integrated nested Laplace approximation (INLA) algorithm [@rue2009approximate] for inference, as implemented by the \texttt{R-INLA} package.
INLA is a deterministic method for approximate Bayesian inference based upon a combination of numerical integration and the Laplace approximation.
INLA is significantly faster than MCMC and has been shown to have comparable accuracy for LGMs in realistic, pre-asymptotic settings.
<!-- Although there are particular conditions under which INLA is not accurate [@rue2017bayesian] they do not apply here, as we illustrate in Appendix \ref{app:inlamcmc} where we compare INLA to MCMC using a large number of iterations. -->

## Model assessment

We assessed each fitted inferential model according to its ability to recover the true underlying value of the probabilities $\rho_i$ at each area in the study region, as well as the calibration of the model's estimates.
<!-- We describe our approach to model assessment in the following sections. -->
<!-- Analogous approaches may be used to check recovery of the intercept parameter $\beta_0$, precision parameter $\tau_\phi$, and, when relevant, the length-scale $l$. -->

### Continuous ranked probability score

The continuous ranked probability score (CRPS) [@matheson1976scoring] gives an overall measure of forecasting performance, and can be seen as a generalisation of the Brier score [@brier1950verification] to distributional forecasts.
For a given fitted model and area $A_i$ let $\rho_i$ have posterior marginal $f(\rho_i) = p(\rho_i \, | \, y)$ and $\omega_i$ be the true value.
Writing $F$ as the cumulative distribution function corresponding to $f$ then
\begin{equation}
\text{CRPS}(f, \omega_i) = \int_{-\infty}^{\infty} (F(\rho_i) - \mathbbm{1} \{\rho_i \geq \omega_i \} )^2 \text{d}\rho_i = \int_{0}^{1} (F(\rho_i) - \mathbbm{1} \{\rho_i \geq \omega_i \} )^2 \text{d}\rho_i, \label{eq:crps}
\end{equation}
where $\mathbbm{1}$ denotes the indicator function and the second equality follows from $0 \leq \rho_i \leq 1$.
The minimum possible value of the CRPS is zero, corresponding to a a point mass correctly forecast at the true value $f(\rho_i) = \delta_{\omega_i}$.
The CRPS is a strictly proper scoring rule such that the uniquely best approach to minimising the score is for the model to report its true probabilistic beliefs about the quantity in question [@gneiting2007strictly].
The logarithmic score [@good1952rational] given by $\text{LogS}(f, \omega_i) = \log f(\omega_i)$ is another popular strictly proper scoring rule, though in line with the findings of @kruger2020predictive, we found it difficult to compute satisfactorily using kernel density estimation.
In contrast, the CRPS can be evaluated directly using samples $\{\rho_i^s\}_{s = 1}^S \sim p(\rho_i \, | \, y)$ as
\begin{equation}
\text{CRPS}(f, \omega_i) \approx \frac{1}{S} \sum_{s = 1}^S | \rho_i^s - \omega_i | - \frac{1}{2S^2} \sum_{s = 1}^S \sum_{l = 1}^S | \rho_i^s - \rho_i^l |. \label{eq:crpsapprox}
\end{equation}

### Posterior predictive check for coverage

We assessed the coverage of our estimates using posterior predictive checks based on the quantile $q_i = F(\omega_i)$ of the true value within each marginal posterior predictive distribution, computed using numerical integration.
For calibrated models, over repeated simulations, $q_i \sim \mathcal{U}[0, 1]$ such that at any given nominal coverage $1 - \alpha$, the proportion of quantile-based credible intervals containing the true value $\omega_i$ is also be $1 - \alpha$.
To check uniformity we used probability integral transform (PIT) histograms [@dawid1984present] and empirical cumulative distribution function (ECDF) difference plots [@aldor2013power; @sailynoja2021graphical].

## Results

```{r results="asis"}
#' Some of the lines should not be included
lines_remove <- c(1, 3, 4, 5)
cat(readLines("depends/crps-table-rho.txt")[-lines_remove], sep = "\n")
```

# HIV prevalence study \label{sec:hiv}

We compared model performance in estimating HIV prevalence in adults aged $15-49$ across four countries in sub-Saharan Africa: Côte d'Ivoire (which has $n = 33$ districts), Malawi ($n = 28$), Tanzania ($n = 159$) and Zimbabwe ($n = 60$), again varying the spatial random effect specification.
As with the simulation study, \textsf{R} code for this study is available from \url{https://github.com/athowes/areal-comparison}.

## Household survey data

We used data from the most recent publicly available Population Health Impact Assessment (PHIA) survey in each country.
These surveys utilise a complex design, where each individual $j$ in area $i$ has an unequal probability $\pi_{ij}$ of being included in the sample.
A two-stage design in which enumeration areas are first drawn from a stratified sample and then households are chosen using equal probability systematic sampling from within each enumeration area, is common.
To account for the survey design we used sampling weights $w_{ij} = 1 / \pi_{ij}$ to adjust the raw data in each district, obtaining the Kish effective sample size $m_i^\star = (\sum_k w_{ij})^2 / \sum_k w_{ij}^2$ and effective number of cases $y_i^\star$ which may be thought of as what would have been observed had the survey been a simple random sample.

## Model structure

We used the same eight inferential models (Section \ref{sec:simulation}, Table \ref{tab:inferentialmodels}), with a small alteration to the likelihood.
Since the effective number of cases and effective sample size may not be integers, we modelled the effective number of cases $y_i^\star \in \mathbb{R}$ according to a generalised binomial distribution $y_i^\star \sim \text{xBin}(m_i^\star, \rho_i)$, where $m_i^\star \in \mathbb{R}$ is the effective sample size and $\rho_i \in [0, 1]$ is the adult (15-49) HIV prevalence.
The working likelihood under this model for $m^\star_i \geq y^\star_i$ is given by
\begin{equation}
p(y_i^\star \, | \, m_i^\star, \rho_i) = 
\frac{\Gamma(m_i^\star + 1)}{\Gamma(y_i^\star + 1) \Gamma(m_i^\star - y_i^\star + 1)}  \rho_i ^{y_i^\star}  (1 - \rho_i)^{(m_i^\star - y_i^\star)}. \label{eq:xbinomial}
\end{equation}

## Cross-validation \label{sec:cv}

\begin{figure}
    \centering
	\includegraphics[width=\textwidth]{depends/sloo-cv.pdf}
	\caption{The $i$th fold in a SLOO-CV in which the model is fitted on the grey areas $A_{-(i, \delta i)}$ with the blue areas $A_{\delta i}$ held-out, to be assessed in predicting the green area $A_i$.}
	\label{fig:sloo}
\end{figure}

We assessed each model using two cross-validation approaches: (1) a standard leave-one-out cross-validation (LOO-CV), in which at each fold the data from a single district were held-out, and (2) a spatial leave-one-out cross-validation (SLOO-CV), in which at each fold the data from a single district and each of its neighbouring districts were removed.
<!-- We performed both types of cross-validation manually, as we found approximations that avoid refitting the model, such as the built-in conditional predictive ordinate statistic in `R-INLA` package [@held2010posterior] and the Pareto smoothed importance sampling [@vehtari2015pareto] approach implemented in the `loo` package [@vehtari2017practical], were inaccurate in this setting. -->
<!-- This might be because individual observations in spatial random effect models can exert high influence toward local parameters. -->

### Leave-one-out cross-validation

In the $i$th LOO-CV fold, the model was fit using the data $y_{-i}$ and assessed according to its prediction on $y_i$.
We assessed forecasting performance using the CRPS, at the level of the data $y_i$ rather than at the level of the prevalence $\rho_i$.
To compute the value of CRPS for the $i$th fold we use samples $\{ y_i^s \}_{s = 1}^S$ from the LOO posterior predictive distribution $p(y_i \, | \, y_{-i})$ giving $\text{LOO-CRPS}_i = \frac{1}{S} \sum_{s = 1}^S | y_i^s - y_i | - \frac{1}{2S^2} \sum_{s = 1}^S \sum_{l = 1}^S | y_i^s - y_i |. \label{eq:crpsapprox2}$

### Spatial leave-one-out cross-validation

In the presense of structural dependencies, like spatial dependence, LOO-CV tends to underestimate predictive error [@roberts2017cross].
To counteract this effect we modified the spatial leave-one-out (SLOO) approach of @le2014spatial by leaving-out the block $(i, \delta i)$ (Figure \ref{fig:sloo}) during the $i$th fold, increasing the extent to which the training and validation sets are conditionally independent.
From the SLOO posterior predictive distribution $p(y_i \, | \, y_{-(i, \delta i)})$  we analogously computed $\text{SLOO-CRPS}_i$.

## Results

```{r results="asis"}
#' Some of the lines should not be included
lines_remove <- c(1)

#' An obnoxious number of escape characters
readLines("depends/metric-table.txt")[-lines_remove] %>%
  stringr::str_replace(pattern = "\\(\\\\\\$n\\\\\\$", replacement = "($n$") %>%
  cat(sep = "\n")
```

# Discussion \label{sec:discussion}

# Funding {-}

AH was supported by the EPSRC Centre for Doctoral Training in Modern Statistics and Statistical Machine Learning (EP/S023151/1).
AH, JWE were supported by the Bill and Melinda Gates Foundation (OPP1190661).
JWE was supported by UNAIDS and National Institute of Allergy and Infectious Disease of the National Institutes of Health (R01AI136664).
SF was supported by the EPSRC (EP/V002910/1).
This research was supported by the MRC Centre for Global Infectious Disease Analysis (MR/R015600/1), jointly funded by the UK Medical Research Council (MRC) and the UK Foreign, Commonwealth \& Development Office (FCDO), under the MRC/FCDO Concordat program and is also part of the EDCTP2 programme supported by the European Union.

For the purpose of Open Access, the authors have applied a CC BY public copyright licence to any Author Accepted Manuscript (AAM) version arising from this submission.

# Acknowledgements {-}

Yidan Xu undertook the Mary Lister McCammon Summer Research Fellowship 2019 on related work.
AH thanks Robert Ashton for help with \textsf{R} package development, and Harrison Zhu, Theo Rashid, Samir Bhatt, Tim Lucas, Elizaveta Semenova, Marta Blangiardo and Oliver Ratmann for helpful conversations.

# Disclaimer {-}

The findings and conclusions in this manuscript are those of the authors and do not necessarily represent the official position of the funding agencies.

\clearpage

# References {#references .unnumbered}
